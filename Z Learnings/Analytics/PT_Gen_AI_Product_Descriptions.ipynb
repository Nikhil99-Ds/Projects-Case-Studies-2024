{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af1056c1-4e34-4e0f-85d5-adfa814e62bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install timeout_decorator -q\n",
    "!pip install wordcloud -q\n",
    "!pip install language-tool-python -q\n",
    "!pip install openai==0.28 -q\n",
    "!pip install databricks-feature-store -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31081ab8-8bcb-43b2-847a-29dfb275df7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33d8193e-ea50-4c63-a159-a3f4453127f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "# from wordcloud import WordCloud\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "# from timeout_decorator import timeout\n",
    "import time\n",
    "from databricks.feature_store import FeatureStoreClient\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from itertools import chain\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5625620-8df4-43dd-8cbd-8ee4d56e3888",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c14adc-dd00-4860-b6c6-eb53ad174a9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select *\n",
    "# from abfrl_catalog.ml_tables.gen_ai_product_description\n",
    "# where a_flagged_style = '0'\n",
    "# limit 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf11a85d-0eb0-4661-8c9a-c2efd658e329",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select *\n",
    "# from abfrl_catalog.pfrl_vrdm.rsh_ean_details\n",
    "# where brand = 'Pantaloons'\n",
    "# and modified_ts >= (current_timestamp() - interval 24 hour)\n",
    "# and sub_brand = 'Byford'\n",
    "# limit 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d77e370d-ec44-4b52-bfd7-a2152bec0c59",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql('''\n",
    "select distinct StyleCode as Style_code, \n",
    "                Gender,\n",
    "                REPLACE(Product_Type, '&amp;', 'and') as Category,\n",
    "                Sub_brand as Brand,\n",
    "                ProductName as Short_Description,\n",
    "                regexp_replace(ShortDescription, '\\\\d+|%|&#\\d+;|<p>|</p>|<b>|</b>|cm|&nbsp|<p class=\"description\">|;', '') AS Description,\n",
    "                REPLACE(Accessories,  '&amp;', 'and') as Accessory_Type, -- Replacing `&`` with `&`\n",
    "                REPLACE(Collection_1, '&amp', 'and') as Collection,\n",
    "                Color_1 as Color, \n",
    "                Cuffs_1 as Cuff,\n",
    "                Fit_1 as Fit,\n",
    "                Front_Opening,\n",
    "                REGEXP_REPLACE(\n",
    "                  REPLACE(\n",
    "                    REPLACE(\n",
    "                      REPLACE(\n",
    "                        REGEXP_REPLACE(coalesce(Upper_Material, Material_1), '[0-9%.-]', ''),\n",
    "                        '&amp;', ','),\n",
    "                     ' and ', ' , '),\n",
    "                   '&comma;', ''), \n",
    "                '\\\\belas[^ ]*\\\\b', 'elastane') AS Material,\n",
    "                Neck_1 as Neck,\n",
    "                Occasion_1 as Occasion,\n",
    "                Pattern_1 as Pattern,\n",
    "                Power_Source,\n",
    "                Shoe_Type,\n",
    "                Shorts_Type,\n",
    "                Sleeves_1 as Sleeve,\n",
    "                Sole_Material,\n",
    "                Strap_Color,\n",
    "                Style_1 as Style,\n",
    "                regexp_replace(Suit_Front, 'Single Breasted - ', '') as Suit_front,\n",
    "                Trouser_Front,\n",
    "                Wash_1 as Wash,\n",
    "                Waist_Rise\n",
    "from abfrl_catalog.pfrl_vrdm.rsh_ean_details\n",
    "where Brand='Pantaloons'\n",
    "and StyleCode in ('TA11012707357', 'TA110127074227', 'BY11012149720', 'TJ110124687313')\n",
    "               ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95b27f17-5719-496f-8c08-67b3dfb9d481",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.display()\n",
    "# df = df.limit(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b3c0511-3aaf-4488-89b6-550fc5f42585",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to check fo a particular brand/product/ etc.\n",
    "# df.filter(df.Material.contains('Polyester,  Viscose And  Elastic')).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18328fc2-fda7-454b-9340-168dde96d195",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.select('Neck').distinct().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50e16814-9250-4028-927f-64f638eac4f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_count = df.select(\"Style_Code\").distinct().count()\n",
    "source_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a44f71bc-e039-4e2e-8835-90c9df50d937",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source = df.select(\"Style_Code\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e19979-ea04-414d-acd3-7868aa1fc6f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.select('Style_Code',\"Gender\", \"Color\", \"Material\", \"Fit\", \"Occasion\",\"Neck\",\"Pattern\",'Sleeve','Cuff',\"Front_Opening\",'Sole_Material','Wash','Category','Brand','Description','Power_Source','Shorts_Type','Shoe_Type','Accessory_Type','Waist_Rise','Suit_front','Trouser_Front','Strap_Color','Short_Description','collection')\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff2edf98-b6a5-4f98-ac7c-19e8b7237dea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e740ad3-de3a-44f4-ab6c-db43fa02b7b0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Preprocessing & Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e077c221-199d-47df-8f90-2c927890cbb9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# brand level cleaning i.e. changing the names to a standardised name\n",
    "df = df.withColumn('brand',when(col('brand')=='LP','Louis Philippe')\n",
    "                        .when(col('brand')=='VH','Van Heusen')\n",
    "                        .when(col('brand')=='AS','Allen Solly')\n",
    "                        .when(col('brand')=='LP Jeans','Louis Philippe Jeans')\n",
    "                        .when(col('brand')=='Tribe','Allen Solly Tribe')\n",
    "                        .when(col('brand')=='V Dot', 'V Dot by Van Heusen')\n",
    "                        .when(col('brand')=='Vdot', 'V Dot by Van Heusen')   #addition\n",
    "                        .when(col('brand')=='Allen Solly Jeans','Allen Solly')\n",
    "                        .when(col('brand')=='Allen Solly Woman','Allen Solly')\n",
    "                        .when(col('brand')=='Van Heusen Woman','Van Heusen')\n",
    "                        .when(col('brand')=='Van Heusen Woman','Van Heusen')\n",
    "                        .otherwise(col('brand')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5bfe1f-e46d-4763-b01d-a3cee16b2beb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# category level cleaning i.e. changing the names based on Front_Opening\n",
    "# changes to be made based on PT data\n",
    "df = df.withColumn('Front_Opening', \n",
    "                   when(((initcap(col('Category'))=='Jeans')\n",
    "                        |(initcap(col('Category'))=='Trousers')\n",
    "                        |(initcap(col('Category'))=='Skirt')\n",
    "                        |(initcap(col('Category'))=='Shorts')\n",
    "                        |(initcap(col('Category'))=='Pants')\n",
    "                        #|(initcap(col('Category'))=='Antiviral Jeans')\n",
    "                        |(initcap(col('Category'))=='Bermuda')\n",
    "                        |(initcap(col('Category'))=='Cargo')) \n",
    "                        &((initcap(col('Front_Opening'))=='Zip Front')\n",
    "                        |(initcap(col('Front_Opening'))=='Zip-Button Front')), None)\n",
    "                        .otherwise(col('Front_Opening')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbfb8e7f-34ba-444b-ae00-3d6179e529f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Pattern level cleaning i.e. changing names based on Pattern\n",
    "# changes to be made based on PT data\n",
    "df = df.withColumn('Pattern', when(initcap(col('Pattern')).isin('Ouch','Flat Front','Crop Tops','Patterned'), None)\\\n",
    "                              .when(lower(col('Pattern'))=='floral,floral,floral', 'floral')\\\n",
    "                              .when(lower(col('Pattern'))=='print-tropical', 'tropical')\\\n",
    "                              .when(initcap(col('Pattern'))=='Colorblock', 'color block')\\\n",
    "                              .when(initcap(col('Pattern'))=='Striped', 'stripe')\\\n",
    "                              .when(initcap(col('Pattern'))=='Checks', 'Check')\\\n",
    "                              .when(initcap(col('Pattern'))=='Checked', 'Check')\\\n",
    "                              .when(initcap(col('Pattern'))=='Solids', 'solid')\\\n",
    "                              .when(initcap(col('Pattern'))=='Animal Printed', 'animal print')\\\n",
    "                              .when(initcap(col('Pattern'))=='Dots', 'dot')\\\n",
    "                   .otherwise(col('Pattern')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d81f2ac4-4c8b-4e22-a0e0-2bd91f5e1ccb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#not needed for PT\n",
    "# df = df.withColumn('Color', when(initcap(col('Color'))=='Trasparent', 'transparent').otherwise(col('Color')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada17444-0fb9-4e4d-b96d-b15a1ab838da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# add Material's substitute values\n",
    "df = df.withColumn(\"Material\", trim(regexp_replace(col(\"Material\"), \"^/\", \"\")))\\\n",
    ".withColumn(\"Material\", regexp_replace(col(\"Material\"), \"/\", \",\"))\\\n",
    ".withColumn('Material', when(upper(col('Material'))=='PU', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='polyurethane and  polyester', 'vegan leather and polyester')\\\n",
    "  .when(col('Material')=='Cotton,  Naylon and  Spandex', 'Cotton,  Nylon and  Spandex')\\\n",
    "  .when(lower(col('Material'))=='Lather', 'Leather')\\\n",
    "  .when(upper(col('Material'))=='CVC', 'cotton and polyester')\\\n",
    "  .when(initcap(col('Material'))=='Polyurethane Leather', 'vegan leather')\\\n",
    "  .when(initcap(col('Material'))=='Terylene Rayon', 'Terylene Rayon')\\\n",
    "  .when(initcap(col('Material'))=='Polyurethane And  Tc', 'vegan leather and polyester')\\\n",
    "  .when(initcap(col('Material'))=='Cotton,  Naylon And  Spandex', 'Cotton,  Nylon and  Spandex')\\\n",
    "  .when(initcap(col('Material'))=='Micro Fibro', 'Micro Fiber')\\\n",
    "  .when(initcap(col('Material'))=='Tie &amp; Pocket Square   Polyester', 'Polyester')\\\n",
    "  .when(initcap(col('Material'))=='Polyester,  Viscose And  Elastic', 'Polyester,  Viscose and  Elastane')\\\n",
    "  .when(initcap(col('Material'))=='Polyester Viscose Elasti', 'Polyester Viscose Elastane')\\\n",
    "  .when(initcap(col('Material'))==')Polyester, Rayon And  Elastine', 'Polyester, Rayon and  Elastane')\\\n",
    "  .when(lower(col('Material'))=='polyester and  viscose and   elastene', 'Polyester and  Viscose and   Elastane')\\\n",
    "  .when(lower(col('Material'))=='polyester, viscose and  elastien', 'Polyester, Viscose and  Elastane')\\\n",
    "  .when(lower(col('Material'))=='p,olyester,  viscose and  spandex', ' Polyester,  Viscose and  Spandex')\\\n",
    "  .when(lower(col('Material'))=='cotton and  polyester and  stretch', 'elastane - multiple ends')\\\n",
    "  .when(initcap(col('Material'))=='Poly Cotton Blend', 'polyester and cotton')\\\n",
    "  .when(lower(col('Material'))=='cotton and  spadnex', 'Cotton and  spandex')\\\n",
    "  .when(initcap(col('Material'))=='Polyamide And Spandex', 'nylon and elastane')\\\n",
    "  .when(lower(col('Material'))=='polyamide and   elastane', 'nylon and elastane')\\\n",
    "  .when(lower(col('Material'))=='cotton,  polyester and  sparkle', 'spandex (for sparkle)')\\\n",
    "  .when(initcap(col('Material'))=='Polyurethane Leather', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='polyester, viscose and e lasti', 'elastane')\\\n",
    "  .when(lower(col('Material'))=='terylenerayon', 'terylene and rayon')\\\n",
    "  .when(initcap(col('Material'))=='Micro Fibre', 'Micro Fiber')\\\n",
    "  .when(lower(col('Material'))=='lambswool and  nylon', 'lamb wool')\\\n",
    "  .when(lower(col('Material'))=='pu and cotton blend', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='tc,  pu and others', 'vegan leather')\\\n",
    "  .when(initcap(col('Material'))=='Cottom', 'Cotton')\\\n",
    "  .when(lower(col('Material'))=='pu leather', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='polyamide and  Eeastane', 'nylon')\\\n",
    "  .when(lower(col('Material'))=='polyamide and  spandex', 'nylon')\\\n",
    "  .when(initcap(col('Material'))=='Polyster  Viscose', 'polyester')\\\n",
    "  .when(initcap(col('Material'))=='Polyurethane', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))==' merino and  acrylic&comma;', 'merino and acrylic')\\\n",
    "  .when(initcap(col('Material'))=='Polyurethane', 'vegan leather')\\\n",
    "  .when(initcap(col('Material'))=='Synthetic', None)\\\n",
    "  .when(initcap(col('Material'))=='Synthetic Leather', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='polyurethane and mesh', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='polyurethane and textile', 'vegan leather')\\\n",
    "  .when(initcap(col('Material'))=='Weaved Tape', None)\\\n",
    "  .when(initcap(col('Material'))=='Weaved Tape', None)\\\n",
    "  .when(lower(col('Material'))=='fabric', None)\\\n",
    "  .when(lower(col('Material'))=='cloth cast llp sitapur industrial area, g, phaseiii jaipur ', None)\\\n",
    "  .when(lower(col('Material'))=='contemporary exports llp , kamal v complex , mathura road sector  ,  faridabad , hariyana', None)\\\n",
    "  .when(initcap(col('Material'))=='Accessory', None)\\\n",
    "  .when(initcap(col('Material'))=='Polyuethane', 'vegan leather')\\\n",
    "  .when(lower(col('Material'))=='knit and polyurethane', 'Knit and Vegan Leather')\\\n",
    "  .when(lower(col('Material'))=='flyknit and polyurethane', 'Flyknit and Vegan Leather')\\\n",
    "#-----Adding Spelling Rectifications----#\n",
    "  .when(initcap(col('Material'))==' Cotton ,  Elastanee', 'Cotton ,  Elastane')\\\n",
    "  .when(initcap(col('Material'))==' Cotton Polyester Elastan', 'Cotton, Polyester, Elastane')\\\n",
    "  .when(initcap(col('Material'))==' Nylon ,  Elastanee', 'Nylon ,  Elastane')\\\n",
    "  .when(lower(col('Material'))==' cotton,  nylon an  spandex', 'cotton, nylon, spandex')\\\n",
    "  .when(initcap(col('Material'))==\" Cotton,  Polyester ,  ElastaneSuper Slim Fit Jeans\", 'cotton,  polyester ,  elastane')\\\n",
    "  .when(initcap(col('Material'))==' Cotton,  Nylon ,  Elastanee', 'cotton, nylon, elastane')\\\n",
    "  .when(initcap(col('Material'))==' Polyester Viscose Spande', ' polyester, viscose, spandex')\\\n",
    "  .when(initcap(col('Material'))=='` Cotton', 'cotton')\\\n",
    "  .when(initcap(col('Material'))=='Polyester  Spandex', 'polyester, spandex')\\\n",
    "  .when(initcap(col('Material'))=='Poly Nylon Blend', 'polyester, nylon blend')\\\n",
    "  .when(initcap(col('Material'))==' Polyester,  Viscose  Cotton ,  Spandex', ' polyester,  viscose, cotton ,  spandex')\\\n",
    "  .when(initcap(col('Material'))==' Cotton+ Spandex', ' cotton, spandex')\\\n",
    "  .when(initcap(col('Material'))==' Cotton,  Elastane ,  ElastaneSuper Slim Fit Jeans', 'cotton, elastane')\\\n",
    "  .when(initcap(col('Material'))==' Cotton ,  Ployester', 'cotton, polyester')\\\n",
    "  .when(initcap(col('Material'))==' Cotton ,  Ployester', 'cotton, polyester')\\\n",
    "  .when(initcap(col('Material'))=='^ Cotton', 'cotton')\\\n",
    "  .when(upper(col('Material')).like('%PU%'), 'vegan leather')\\\n",
    "  .when(initcap(col('Material'))=='c  p   el', 'cotton polyester spandex')\\\n",
    "  .when(initcap(col('Material'))=='cotton  poly  lycra  to  ozs option', 'cotton polyester spandex')\\\n",
    "  .when(initcap(col('Material'))=='co  poly  spdx', 'cotton polyester spandex')\\\n",
    "  .when(initcap(col('Material'))=='c  p  vis ray  el', 'cotton polyester viscose rayon spandex')\\\n",
    "  .when(initcap(col('Material'))=='cotton  spandex sj', 'cotton spandex')\\\n",
    "  .when(initcap(col('Material'))=='c  p  vis,ray  el', 'cotton polyester viscose rayon spandex')\\\n",
    "  .when(initcap(col('Material'))=='cotton  spenx', 'cotton  spandex')\\\n",
    "  .when(initcap(col('Material'))=='ctn tencil spandex', 'cotton tencil spandex')\\\n",
    "  .when(initcap(col('Material'))=='cotton  polyester  elastane   oz', 'cotton  polyester  elastane')\\\n",
    "  .when(lower(col('Material')).isin('other', 'fibers', 'gsm', 'accessory', 'ozs', 'oz', 'tshirt', 'tshirts', 'top', 'tops', 'shirt', 'shirts', 'jacket', 'jackets','aeo stretch boxer short multipack'),'')\\\n",
    "  .otherwise(col('Material')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e985031c-68ff-4399-94c7-d5009418197a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Cuff', when(lower(col('Cuff'))=='regular cuff', '').when(lower(col('Cuff'))=='double cuff', 'double').otherwise(col('Cuff')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a77e436-5628-4aaf-93c5-df0c604cee08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Sleeve', regexp_replace(lower(col('Sleeve')),\" sleeve\",\"\"))\\\n",
    "       .withColumn('Sleeve', regexp_replace(lower(col('Sleeve')),\" sleeves\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68eb52c6-0004-4eb7-a899-93da10ffdabd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Sleeve', when(lower(col('Sleeve'))=='fulls', 'full')\\\n",
    "  .when(lower(col('Sleeve'))=='longs', 'long')\\\n",
    "  .when(lower(col('Sleeve'))=='halfs', 'half')\\\n",
    "  .when(lower(col('Sleeve'))=='shorts', 'short')\\\n",
    "  .when(lower(col('Sleeve'))=='3/4ths', '3/4th')\\\n",
    "  .when(lower(col('Sleeve'))=='caps', 'cap')\\\n",
    "  .otherwise(lower(col('Sleeve')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d779f90-b4ec-470b-8e01-692441916235",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Fit', when(initcap(col('Fit'))=='Beat Fit', None).otherwise(col('Fit')))\n",
    "df = df.withColumn('Fit', when(lower(col('Fit'))=='slim fit', 'slim')\\\n",
    "  .when(lower(col('Fit'))=='regular fit', 'regular')\\\n",
    "  .when(lower(col('Fit'))=='custom fit', 'custom')\\\n",
    "  .when(lower(col('Fit'))=='ultra slim fit', 'ultra slim')\\\n",
    "  .when(lower(col('Fit'))=='snug fit', 'snug')\\\n",
    "  .when(lower(col('Fit'))=='skinny fit', 'skinny')\\\n",
    "  .when(lower(col('Fit'))=='smart fit', 'smart')\\\n",
    "  .when(lower(col('Fit'))=='super slim fit', 'super slim')\\\n",
    "  .when(lower(col('Fit'))=='carrot fit', 'carrot')\\\n",
    "  .when(lower(col('Fit'))=='ankle skinny fit', 'ankle skinny')\\\n",
    "  .when(lower(col('Fit'))=='straight fit', 'straight')\\\n",
    "  .when(lower(col('Fit'))=='sport fit', 'sport')\\\n",
    "  .when(lower(col('Fit'))=='jegging fit', 'jegging')\\\n",
    "  .when(lower(col('Fit'))=='comfort fit', 'comfort')\\\n",
    "  .when(lower(col('Fit'))=='classic fit', 'classic')\\\n",
    "  .when(lower(col('Fit')).isin('original','shirt','fit','t-shirt','v neck','shoulder strap','babydoll','skinny kick','wrap','jeans','tie & dye','tomgirl','jeggings','jegging','shorts','silhouette','three fourth sleeve','sleeveless','short sleeve','kick','textured','solid'),'')\\\n",
    "  .otherwise(lower(col('Fit'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54caae2c-660b-4fab-a4d3-85123b4d6115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Neck', when(initcap(col('Neck'))=='Crew Neck', 'crew')\\\n",
    "  .when(initcap(col('Neck'))=='Polo Neck', 'polo')\\\n",
    "  .when(initcap(col('Neck'))=='Round Neck', 'round')\\\n",
    "  .when(initcap(col('Neck'))=='Stylized Neck', 'stylized')\\\n",
    "  .when(initcap(col('Neck'))=='V Neck', 'v')\\\n",
    "  .when(initcap(col('Neck'))=='Square Neck', 'square')\\\n",
    "  .when(initcap(col('Neck'))=='Hooded Neck', 'hooded')\\\n",
    "  .when(initcap(col('Neck'))=='V-Neck', 'V')\\\n",
    "  .when(initcap(col('Neck'))=='Henley Neck', 'henley')\\\n",
    "  .when(initcap(col('Neck'))=='Slit Neck', 'slit')\\\n",
    "  .when(initcap(col('Neck'))=='Turtle Neck', 'turtle')\\\n",
    "  .when(initcap(col('Neck'))=='Boat Neck', 'boat')\\\n",
    "  .when(initcap(col('Neck'))=='Cowl Neck', 'cowl')\\\n",
    "  .when(initcap(col('Neck'))=='High Neck', 'high')\\\n",
    "  .when(initcap(col('Neck'))=='Sweetheart Neck', 'sweetheart')\\\n",
    "  .when(initcap(col('Neck'))=='Collar Neck', 'collar')\\\n",
    "  .when(initcap(col('Neck'))=='Peterpan Neck', 'peterpan')\\\n",
    "  .when(initcap(col('Neck'))=='Scoop Neck', 'scoop')\\\n",
    "  .when(initcap(col('Neck'))=='Peter Pan Neck', 'peter pan')\\\n",
    "  .when(initcap(col('Neck'))=='Round Crew Neck', 'round crew')\\\n",
    "  .when(initcap(col('Neck'))=='Halter Neck', 'halter')\\\n",
    "  .when(initcap(col('Neck'))=='Mock Neck', 'mock')\\\n",
    "  .otherwise(lower(col('Neck'))\n",
    "  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "717a9239-64ef-41cd-a52a-b3cb2d8fbcb7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Sole_Material', when(initcap(col('Sole_Material'))=='Polyurethane', None)\\\n",
    "                   .otherwise(col('Sole_Material')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f72e029-ee24-449d-8e97-68916849917c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('Category', when(lower(col('Category'))=='shirts', 'shirt')\\\n",
    "  .when(lower(col('Category'))=='trousers', 'trouser')\\\n",
    "  .when(lower(col('Category'))=='track pants', 'track pant')\\\n",
    "  .when(lower(col('Category'))=='t-shirts', 't-shirt')\\\n",
    "  .when(lower(col('Category'))=='button up shirts', 'button up shirt')\\\n",
    "  .otherwise(lower(col('Category')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e35854c-34e9-4c40-9bed-647fc4b11fb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_lower = ['Gender','Category','Accessory_Type', 'Color', 'Cuff', 'Fit', 'Material', 'Neck', 'Occasion', 'Pattern', 'Power_Source', 'Shoe_Type', 'Shorts_Type', 'Sleeve','Sole_Material', 'Strap_Color', \n",
    "                   # 'Style',\n",
    "                     'Suit_Front', 'Trouser_Front', 'Wash', 'Waist_Rise']\n",
    "\n",
    "for column in columns_to_lower:\n",
    "    df = df.withColumn(column, lower(col(column)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ece539d2-9013-437e-98e0-8daa7fd85818",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2e0a058-49b1-4b28-9e39-1f5294d19ff4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mat_df = df.select('Material')\n",
    "material_result = mat_df.toPandas()['Material'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a860c763-f05f-43ab-acb0-754a46ae468d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mat_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f6a1c88-405d-45ee-bf19-939e950e5fe8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(material_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc433741-9ebd-4502-980d-ad1133765537",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "chunks = int(np.ceil(len(material_result)/100))\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a8213f-ddb0-43d6-9b33-399cd1ea31ca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Open-AI Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c384312-c635-459f-98b3-b18b5d961d9a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://abfopenai-analytics.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = '81d383be2dfe43f5aae90e6071ed9fd8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b694a81e-7e36-4d4c-9e4d-89931f0a93d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_processed_material(material_list,chunks,chunk_size):\n",
    "  final_list = []\n",
    "  for chunk in range(chunks):\n",
    "      start = chunk*chunk_size\n",
    "      end = start+chunk_size\n",
    "      # print(start,end)\n",
    "      prompt = f\"\"\"\n",
    "                        Instructions:\n",
    "                        '''\n",
    "                        - Clean the list of product fabric material values for cataloguing of fashion products on a website.\n",
    "                        \n",
    "                        - Ensure the output contains detailed values with no spelling mistakes or short forms.\n",
    "\n",
    "                        - Ensure the output is in lowercase only apart from acronyms. Eg. 'Cotton' should be 'cotton', 'EVA' should be 'EVA'.\n",
    "\n",
    "                        - Remove all special characters except comma.\n",
    "\n",
    "                        - Convert all occurrences of PU, P.U., Polyurethane to 'vegan leather'.\n",
    "\n",
    "                        - Set all values that are not product materials or abbreviations for product materials to null.   \n",
    "\n",
    "                        - Refine the list to extract product fabric material names, accurately correcting misspellings. Ensure materials listed together in a single string are separated. For example, 'rayon polyester' becomes 'rayon, polyester', while 'polyester lycra' becomes 'polyester, lycra' or 'line,  cotton' becomes 'cotton'. These examples serve as references; ensure dynamic updates for all strings.\n",
    "\n",
    "                        - Generate processed product fabric material names for strings containing materials, while assigning null values to strings containing other values. For instance, if the input string is 'rayon polyester', the processed material name will be 'rayon, polyester' while for 'cotton  viscose' output will be 'cotton, viscose'. Similarly, if the string contains a product category like 'tie, pocket square, polyester', the output will focus solely on 'polyester' or if string is 'iron  glass  plastic  polyster' then output will be 'polyester'.\n",
    "\n",
    "\n",
    "                        - Refine the list to extract only the product fabric names, and strictly omit the occurance of other words like cufflinks, metals, alloys, product categories like shirt, and any other irrelevant values from input string.For example, if the input is \"tshirt cotton\", the output should be \"cotton\". Similarly, strings like \"polyester, cufflinksteel\" should result in \"polyester\". Ensure that only product fabric names are retained in the output, while all other values are discarded. Additionally, strings like \"tie,pocket square polyester,lapel pin, metal, alloy , lapel pinsteel,cufflinks,alloy,metal\" should yield \"polyester\". Ensure dynamic updates for all strings.\n",
    "\n",
    "                        - Present the output in a list of tuple where the key represents the original input and the value signifies the processed output. Ensure that in the output value, materials separated by commas are unique.\n",
    "\n",
    "                        - Refine the output to consist solely of a list of tuples without any unnecessary characters like ellipses (...) within the string or in the tuples themselves. Ensure that each tuple contains proper strings without any additional information. For instance, avoid strings like \"('ae ne(x)t level...\" or [('plastic, glass', None), ...]. It's crucial that the output dynamically adapts to the input data. This refinement is vital to ensure the integrity and usability of the output as a valid list of tuples.\n",
    "\n",
    "                        - Ensure that each tupple is separated by single comma.\n",
    "                        \n",
    "                        '''                     \n",
    "\n",
    "                        Please process the below given list of product materials according to the instructions above.\n",
    "                        ```{material_list[start:end]}```                             \n",
    "                        \"\"\"\n",
    "\n",
    "      response = openai.ChatCompletion.create(engine=\"abfrlgpt\",\n",
    "                                              temperature = 0.2, \n",
    "                                              messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Data Preprocessing Specialist for a fashion brand, tasked with correcting the material name by following the instructions enclosed in triple single quotes(''').\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}])\n",
    "      output = response['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "      start = output.find('[')\n",
    "      end = output.find(']')\n",
    "      pattern = r\"\\([^)]*\\.\\.\\.[^)]*\\)\"\n",
    "      tuples_with_ellipses = re.findall(pattern, str(output[start:end+1])) \n",
    "      filtered_string = re.sub(pattern, '', str(output[start:end+1]))\n",
    "      output_string = re.sub(r',\\s*,',',', filtered_string)\n",
    "      output_string = output_string.replace(\"\"\"\\n\"\"\",\"\")\n",
    "      print(output_string)\n",
    "      material_output = ast.literal_eval(output_string)\n",
    "      final_list = final_list+material_output \n",
    "\n",
    "  return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ab8067c-9cd4-4dfa-b218-4781f5f5bdba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cotton', None), ('blended', None)]\n"
     ]
    }
   ],
   "source": [
    "processed_material = get_processed_material(material_result, chunks, 100)\n",
    "schema = StructType([\n",
    "    StructField(\"Material\", StringType(), nullable=True),\n",
    "    StructField(\"Processed_Material\", StringType(), nullable=True)\n",
    "])\n",
    "material_output_df = spark.createDataFrame(data=processed_material,schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3504881a-39e6-49f2-b348-01809833a6e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# material_output_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f266d9-9202-48cc-805e-15bd1591663b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # missed_materials = list(set(material_output_df.filter(col('Processed_Material').isNull()) \\\n",
    "# #                             .select('Material').rdd.map(lambda row: row.Material).collect()))\n",
    "\n",
    "# missed_materials = material_output_df.filter(col('Processed_Material').isNull()).select('Material').toPandas()['Material'].unique().tolist()\n",
    "# chunks = int(np.ceil(len(missed_materials)/20))\n",
    "\n",
    "# columns = StructType([StructField('Material',StringType(), True),\n",
    "#                       StructField('Missed_Processed_Material',StringType(), True)])\n",
    "# missed_materials_output_df = spark.createDataFrame([],schema =  columns)\n",
    "\n",
    "# retries = 0\n",
    "# while len(missed_materials)>0 and retries<5:\n",
    "#   processed_material = get_processed_material(missed_materials,chunks,20)\n",
    "#   missed_material_df = spark.createDataFrame(data=processed_material,schema= columns)\n",
    "#   # print('Length of missed material list',len(missed_materials))\n",
    "#   missed_materials_output_df = missed_materials_output_df.union(missed_material_df)\n",
    "#   # missed_materials = list(set(missed_material_df.filter(col('Missed_Processed_Material').isNull()) \\\n",
    "#   #                           .select('Material').rdd.map(lambda row: row.Material).collect()))\n",
    "#   missed_materials = missed_material_df.filter(col('Missed_Processed_Material').isNull()).select('Material').toPandas()['Material'].unique().tolist()\n",
    "#   retries+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00785387-f523-4087-b76d-df3e0327e1cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 1: Processing 2 materials\n[('cotton', None), ('blended', None)]\nRetry 2: Processing 2 materials\n[('cotton', None), ('blended', None)]\nRetry 3: Processing 2 materials\n[('cotton', None), ('blended', None)]\nRetry 4: Processing 2 materials\n[('cotton', None), ('blended', None)]\nRetry 5: Processing 2 materials\n[('cotton', None), ('blended', None)]\nFinal list of missed materials: ['cotton', 'blended']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "missed_materials = material_output_df.filter(col('Processed_Material').isNull()).select('Material').toPandas()['Material'].unique().tolist()\n",
    "chunks = int(np.ceil(len(missed_materials)/20))\n",
    "columns = StructType([StructField('Material',StringType(), True),\n",
    "                      StructField('Missed_Processed_Material',StringType(), True)])\n",
    "missed_materials_output_df = spark.createDataFrame([], schema=columns)\n",
    "\n",
    "retries = 0\n",
    "while len(missed_materials) > 0 and retries < 5:\n",
    "    print(f\"Retry {retries+1}: Processing {len(missed_materials)} materials\")\n",
    "    processed_material = get_processed_material(missed_materials, chunks, 20)\n",
    "    \n",
    "    if processed_material:\n",
    "        missed_material_df = spark.createDataFrame(data=processed_material, schema=columns)\n",
    "        missed_materials_output_df = missed_materials_output_df.union(missed_material_df)\n",
    "        missed_materials = missed_material_df.filter(col('Missed_Processed_Material').isNull()).select('Material').toPandas()['Material'].unique().tolist()\n",
    "    else:\n",
    "        print(\"No data returned from get_processed_material\")\n",
    "        break\n",
    "    \n",
    "    retries += 1\n",
    "\n",
    "print(\"Final list of missed materials:\", missed_materials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb9ed7f0-1151-4ac1-a61b-8d09a8b614af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_material_df = material_output_df.join(missed_materials_output_df,on='Material',how='left')\n",
    "final_material_df = final_material_df.withColumn('Processed_Material',coalesce('Processed_Material','Missed_Processed_Material'))\n",
    "final_material_df = final_material_df.distinct()\n",
    "material_df = final_material_df.select(\"Material\",\"Processed_Material\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53188c3f-c888-4bdf-bb16-3a1c734a589a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "material_df = material_df.filter(\"Processed_Material is not null\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecb53a5e-96d0-4264-84c2-0d815112968c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "material_df = df.join(material_df,on='Material',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9bfcfae-bc59-4372-b8ca-451cf9fa6680",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = material_df.drop(\"Material\").withColumnRenamed(\"Processed_Material\",\"Material\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c4395ab-6c9e-4864-87c2-9841a9503325",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19b51a59-eb25-44cf-ae6e-7d7171bd39c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "082b114c-1307-4aa2-8a69-bcb9a856c804",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = df.apply(lambda row: {key: value for key, value in row.items() if value is not None}, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4351eee2-725d-4f35-bade-e2e6a288439c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fbbdf0e-1990-4a7e-b3eb-4ef1801a9803",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Open-AI Description Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ceed8a9-812d-47c5-a4df-0c69100d4cc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_description(result):\n",
    "  final_result = pd.DataFrame()\n",
    "\n",
    "  missed_stylecodes = []\n",
    "  for iteration in range(len(result)):\n",
    "          features = {key:value for key,value in result[iteration].items() if key not in ('Style_Code', 'Short_Description', 'Description', 'product_description')}\n",
    "          prompt = f\"\"\"\n",
    "                  Instructions:\n",
    "                  '''\n",
    "                  - Write a mini-call to action that's both informative and persuasive. What specific benefit will the reader gain by purchasing this product? without using direct call-to-action phrases such as \"purchase\" or \"Shop now\".\n",
    "                  - In up to 70 words using the provided specifications.\n",
    "                  - Emphasize key features and benefits while adhering to grammatical rules.\n",
    "                  - Optimize for SEO tools without using emojis or symbols.\n",
    "                  - Keep the tone inline with the occasion.\n",
    "                  - Avoid word repetition.\n",
    "                  - Make sure the product description is well-formatted and grammatically correct.\n",
    "                  '''\n",
    "                  \n",
    "                  Specifications:\n",
    "                  ```{features}```\n",
    "                  \"\"\"\n",
    "                  #Write a mini-call to action that's both informative and persuasive.\n",
    "                  # - Write a comprehensive product description that is comprehensive and informative.\n",
    "          try:\n",
    "                response = openai.ChatCompletion.create(engine=\"abfrlgpt\",\n",
    "                                                        temperature = 1.2,  # previously : 1.2 --> 0.7\n",
    "                                                        # top_p = 0.1,\n",
    "                                                        messages=[\n",
    "                    # Creative content writer/creative copy writer for a premium fasion retail company.\n",
    "                    {\"role\": \"system\", \"content\": \"Marketing Assistant for a fashion brand, tasked with creating website product descriptions by following the instructions enclosed in triple single quotes(''').\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}])\n",
    "                output = response['choices'][0]['message']['content']\n",
    "                result[iteration]['product_description'] = output\n",
    "\n",
    "                final_result = final_result.append(result[iteration],ignore_index=True)\n",
    "          except Exception as e:\n",
    "              missed_stylecodes.append(result[iteration]['Style_Code'])\n",
    "              print(e)\n",
    "  \n",
    "  return (final_result,missed_stylecodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1afdb161-c333-4728-860e-a47b3b0728c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-ce647236-8e23-4a38-b931-ea/.ipykernel/12940/command-1722934488686471-3847538036:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  final_result = final_result.append(result[iteration],ignore_index=True)\n/home/spark-ce647236-8e23-4a38-b931-ea/.ipykernel/12940/command-1722934488686471-3847538036:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  final_result = final_result.append(result[iteration],ignore_index=True)\n/home/spark-ce647236-8e23-4a38-b931-ea/.ipykernel/12940/command-1722934488686471-3847538036:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  final_result = final_result.append(result[iteration],ignore_index=True)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of stylecodes - 4 length of missed styles - 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-ce647236-8e23-4a38-b931-ea/.ipykernel/12940/command-1722934488686471-3847538036:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  final_result = final_result.append(result[iteration],ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "descriptions_call = get_description(result)\n",
    "final_result = descriptions_call[0]\n",
    "missed_stylecodes = descriptions_call[1]\n",
    "print('length of stylecodes -',len(final_result),'length of missed styles -',len(missed_stylecodes))\n",
    "cnt=1\n",
    "while len(missed_stylecodes)!=0:\n",
    "    missed_stylecodes_df = df[df['Style_Code'].isin(missed_stylecodes)]\n",
    "    # missed_stylecodes_dict = missed_stylecodes_df.rdd.map(lambda row: {key: value for key, value in row.asDict().items() if value is not None}).collect()\n",
    "    missed_stylecodes_dict = missed_stylecodes_df.apply(lambda row: row.dropna().to_dict(), axis=1).tolist()\n",
    "    descriptions_call = get_description(missed_stylecodes_dict)\n",
    "    missed_stylecodes_result = descriptions_call[0]\n",
    "    missed_stylecodes = descriptions_call[1]\n",
    "    final_result = pd.concat([final_result,missed_stylecodes_result],axis=0)\n",
    "    print(\"Iteration -\",cnt)\n",
    "    print('length of stylecodes -',len(missed_stylecodes_result),'length of missed styles -',len(missed_stylecodes))\n",
    "    print(\"=======================================\")\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5724c6e1-4f74-4e89-8627-99716b1de398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# post processing the results\n",
    "def remove_newline(text_description):\n",
    "  processed_text = text_description.replace('\\n', ' ')\n",
    "  return processed_text\n",
    "def multiple_spaces(text_description):\n",
    "  processed_text = re.sub(' +', ' ', text_description)\n",
    "  return processed_text\n",
    "def multiple_dash(text_description):\n",
    "  processed_text = re.sub('-+', '-', text_description)\n",
    "  processed_text = re.sub(' -+', '-', text_description)\n",
    "  processed_text = re.sub('-+ ', '-', text_description)\n",
    "  processed_text = re.sub(' -+ ', '-', text_description)\n",
    "  return processed_text\n",
    "\n",
    "def capitalize_after_full_stop_description(text_description):\n",
    "  result = \"\"\n",
    "  capitalize = False\n",
    "  for char in text_description:\n",
    "    if char == \".\":\n",
    "      capitalize = True\n",
    "      result += char\n",
    "    elif capitalize and char.isalpha():\n",
    "      result += char.upper()\n",
    "      capitalize = False\n",
    "    else:\n",
    "      result += char\n",
    "  return result\n",
    "\n",
    "# Cleanup driver function\n",
    "def cleanup_description(description):\n",
    "  if type(description)!=str:\n",
    "    return description\n",
    "\n",
    "    \n",
    "  brand_list = ['Van Heusen', 'Allen Solly Junior', 'Allen Solly',\n",
    "       'Van Heusen Sport', 'Allen Solly Sport', 'V Dot by Van Heusen',\n",
    "       'Van Heusen Denim Labs', 'Van Heusen Flex', 'Allen Solly Tribe',\n",
    "       'Academy by Van Heusen']\n",
    "  \n",
    "  brand_spelling_correction = {'Allan':' Allen',\n",
    "                               'AllenSolly': ' Allen Solly',\n",
    "                               ' Soli': ' Solly',\n",
    "                               ' Soly': ' Solly',\n",
    "                               ' Alle': ' Allen',\n",
    "                               ' Alan': ' Allen',\n",
    "                               ' Ailen': ' Allen',\n",
    "                               ' Allin': ' Allen',\n",
    "                               ' Allenn': ' Allen',\n",
    "                               \n",
    "                               ' VanHeusen': ' Van Heusen',\n",
    "                               ' Vann':' Van',\n",
    "                               ' Venn': ' Van',\n",
    "                               ' Ven': ' Van',\n",
    "                               ' Huesen': ' Heusen',\n",
    "                               ' Housen': ' Heusen',\n",
    "                               ' Hussen': ' Heusen',\n",
    "                               ' Hewsen': ' Heusen',\n",
    "                               ' Huizen': ' Heusen',\n",
    "                               \n",
    "                               'LouisPhillippe': 'Louis Phillippe',\n",
    "                               ' Lewis': ' Louis',\n",
    "                               ' Loui': ' Louis',\n",
    "                               ' Loois': ' Louis',\n",
    "                               ' Lui': ' Louis',\n",
    "                               ' Luwis': ' Louis',\n",
    "                               ' Lious': ' Louis',\n",
    "                               ' LowisPhillipe': 'Louis Phillippe',\n",
    "                               'Louiss' : \"Louis\"}\n",
    "  \n",
    "  # taking care of Pantaloons with no space\n",
    "  # description = description.replace('Pantaloons', 'Pantaloons ')\n",
    "  description = re.sub(r'\\bPantaloons(?=\\w)', 'Pantaloons ', description)\n",
    "\n",
    "  # taking care of '!!'\n",
    "  description = description.replace('!!', '!')\n",
    "\n",
    "  # checking for spelling mistakes\n",
    "  for k,v in brand_spelling_correction.items():\n",
    "    description = description.replace(k, v)\n",
    "\n",
    "  if 'v dot' in description:\n",
    "    description = description.replace('v dot', 'V Dot')\n",
    "\n",
    "  # for brand in brand_list:\n",
    "  #   small_brand = brand.lower()\n",
    "  #   if small_brand in description.lower():\n",
    "  #     for brand_segment in brand.split():\n",
    "  #       if brand_segment != 'v':\n",
    "  #         description = description.replace(brand_segment.lower(), brand_segment)\n",
    "\n",
    "  #   if str('the '+brand) in description:\n",
    "  #     description = description.replace(str(brand+\"'s\"), brand)\n",
    "  #     description = description.replace(str(brand+\"s\"), brand)\n",
    "  #   elif brand in description:\n",
    "  #     description = description.replace(str(brand+\"'s\"), 'the '+ brand)\n",
    "  #     description = description.replace(str(brand+\"s\"), 'the '+ brand)\n",
    "  for brand in brand_list:\n",
    "    pattern = re.compile(r'\\b' + re.escape(brand.lower()) + r'\\b', re.IGNORECASE)\n",
    "    description = pattern.sub(brand, description)\n",
    "\n",
    "    if 'the ' + brand in description:\n",
    "        description = description.replace(brand + \"'s\", brand)\n",
    "        description = description.replace(brand + \"s\", brand)\n",
    "    elif brand in description:\n",
    "        description = description.replace(brand + \"'s\", 'the ' + brand)\n",
    "        description = description.replace(brand + \"s\", 'the ' + brand)\n",
    "    \n",
    "  description = description.replace('\"\"\"', '')\n",
    "  description = description.replace('\"\"', '')\n",
    "  description = description.replace('\"', '')\n",
    "\n",
    "  description = description.replace(\"'''\", '')\n",
    "  description = description.replace(\"''\", '')\n",
    "  description = description.replace(\" '\", '')\n",
    "  description = description.replace(\"' \", ' ')\n",
    "  description = description.replace(\" \", ' ')\n",
    "  description = description.replace(\"/\", '-')\n",
    "  # description = description.replace(\"'\", '')\n",
    "\n",
    "  description = description.replace('```', '')\n",
    "  description = description.replace('``', '')\n",
    "  description = description.replace('`', '')\n",
    "\n",
    "  # description = description.capitalize()\n",
    "\n",
    "  description = remove_newline(description)\n",
    "  description = multiple_spaces(description)\n",
    "  description = multiple_dash(description)\n",
    "  description = capitalize_after_full_stop_description(description)\n",
    "  \n",
    "  return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c95d5982-22f4-4770-9914-c1d9d68e0e6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def flagging_system(df):\n",
    "  characters_list = ['+', '_', '(', ')', '{', '}', '[', ']', '~', '`', '=', '$', '#','<', '>','^', '\\*', '\\|','', '', '', '',  '', '', '', '',\n",
    "    '','', '','', '','', '','',\n",
    "    '','', '','',\n",
    "    '','', '','',\n",
    "    '','', '','', '','',\n",
    "    '','', '','', ':', '`', '..', '--', ',,', '!','\\\\']\n",
    "  \n",
    "  num_list = ['1','2','3','4','5','6','7','8','9','0', '/']\n",
    "\n",
    "  words_list = ['1744', '2-button', '3-button', '2 button', '3 button', '2 Button', '3 Button', '1-button', \n",
    "                '1 button', '5 button', '5-button', '1-buttoned', '2-buttoned', '3-buttoned', '1 buttoned', '2 buttoned', '3 buttoned' ,'100%', '4 button', '4-Button', '4-button', '100 %', '3/4', '7x7', '4-buttoned', '4 Buttoned', 'pack of 4', 'pack of 2','forever21','Forever21','5 pack','5-pack',\n",
    "                '3 pack','3-pack','2 pack','2-pack']\n",
    "\n",
    "  flag_words_list = ['model', 'Model', 'Buy', 'buy', 'purchase', 'Purchase', 'SEO', 'seo ', 'seo.', 'Shop', 'shop', 'Store', 'store', 'Outlet', 'outlet', 'specification', 'description', 'instruction','Note','Notes','note','notes']\n",
    "\n",
    "  # skipped_categories = ['belt and wallet', 'wallet and key chain']\n",
    "\n",
    "  # brand_list = ['Van Heusen', 'Allen Solly']\n",
    "\n",
    "  # df.dropna(subset = ['product_description'], inplace = True)\n",
    "\n",
    "  result_dict = {key:[] for key in characters_list+num_list}\n",
    "  result_dict['short_desc']          = []\n",
    "  result_dict['long_desc']           = []\n",
    "  result_dict['flag_words']          = []\n",
    "  result_dict['flag_brand']          = []\n",
    "  result_dict['flag_collection']     = []\n",
    "  result_dict['flag_color']          = []\n",
    "  result_dict['flag_category']       = []\n",
    "  result_dict['flag_sleeve']         = []\n",
    "  result_dict['flag_trouser_front']  = []\n",
    "  result_dict['flag_fit']            = []\n",
    "  result_dict['flag_pattern']        = []\n",
    "  # result_dict['flag_material']       = []\n",
    "  result_dict['flag_neck']           = []\n",
    "\n",
    "  counter = 0\n",
    "  columns = ['Style_Code', 'product_description', 'brand', 'Collection', 'Color', 'Category', 'Fit', 'Sleeve', 'Trouser_Front', 'Pattern', 'Material', 'Neck', 'Accessory_Type']\n",
    "  for col in columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "  \n",
    "  for data in df[['Style_Code', 'product_description', 'brand', 'Collection', 'Color', 'Category', 'Fit', 'Sleeve', 'Trouser_Front', 'Pattern', 'Material', 'Neck', 'Accessory_Type']].values: # add brand and category\n",
    "    style_code = data[0]\n",
    "    description = data[1]\n",
    "    brand = data[2]\n",
    "    collection = data[3]\n",
    "    color = data[4]\n",
    "    category = data[5].replace('rompers', 'romper')\n",
    "    fit = data[6]\n",
    "    sleeve = data[7]\n",
    "    trouser_front = data[8]\n",
    "    pattern = data[9]\n",
    "    # material = data[10]\n",
    "    neck = data[11]\n",
    "    # accessories for belt and wallet\n",
    "    accessory = data[12]\n",
    "\n",
    "    # tackling the null descriptions\n",
    "    if type(description)!=str:\n",
    "      val = result_dict['short_desc']\n",
    "      val.extend([style_code])\n",
    "      result_dict['short_desc'] = val\n",
    "      continue\n",
    "\n",
    "    # keeping only the exact brand names\n",
    "    if brand not in description.replace('the ', ''):\n",
    "      val = result_dict['flag_brand']\n",
    "      val.extend([style_code])\n",
    "      result_dict['flag_brand'] = val\n",
    "\n",
    "    # keeping only the exact collection names\n",
    "    if type(collection)==str:\n",
    "      if collection.lower() not in description.lower():\n",
    "        description = description.replace(collection.lower(), collection)\n",
    "      elif collection.lower() not in description.lower():\n",
    "        val = result_dict['flag_collection']\n",
    "        val.extend([style_code])\n",
    "        result_dict['flag_collection'] = val\n",
    "\n",
    "    # keeping only the exact color names\n",
    "    if type(color)==str:\n",
    "      if color.lower() not in description.lower():\n",
    "        val = result_dict['flag_color']\n",
    "        val.extend([style_code])\n",
    "        result_dict['flag_color'] = val\n",
    "\n",
    "  \n",
    "    if brand not in ('Reebok','American Eagle','Forever21'):\n",
    "      if type(category)==str:\n",
    "        if 'wallet and key chain' not in category and 'belt and wallet' not in category:\n",
    "          category = category.replace('and ', '').split(' ')\n",
    "          cat_flag = 0\n",
    "          cufflink_flag = 1\n",
    "          accessory_flag = 0\n",
    "          for category_val in category:\n",
    "            if category_val.strip().replace('-', ' ') not in description.lower().replace('-', ' '):\n",
    "              cat_flag = 1\n",
    "              if 'cufflink' in category_val.strip() and 'cufflink' in description.lower():\n",
    "                cufflink_flag = 0\n",
    "          if cat_flag and cufflink_flag and 'cufflink' not in category:\n",
    "            val = result_dict['flag_category']\n",
    "            val.extend([style_code])\n",
    "            result_dict['flag_category'] = val\n",
    "\n",
    "\n",
    "\n",
    "    # flagging if the description is shorter than 50 in length\n",
    "    if len(description.split(\" \")) < 50:\n",
    "      val = result_dict['short_desc']\n",
    "      val.extend([style_code])\n",
    "      result_dict['short_desc'] = val\n",
    "\n",
    "    # flagging if the description is longer than 90 in length\n",
    "    if len(description.split(\" \")) > 110:\n",
    "      val = result_dict['long_desc']\n",
    "      val.extend([style_code])\n",
    "      result_dict['long_desc'] = val\n",
    "\n",
    "    # flagging if the description contains the unwanted words\n",
    "    for flag_word in flag_words_list:\n",
    "      if flag_word in description:\n",
    "        val = result_dict['flag_words']\n",
    "        val.extend([style_code])\n",
    "        result_dict['flag_words'] = val\n",
    "\n",
    "    # flagging if the description contains the un-wanted characters\n",
    "    for character in characters_list:\n",
    "      if character in description:\n",
    "        val = result_dict[character]\n",
    "        val.extend([style_code])\n",
    "        result_dict[character] = val\n",
    "\n",
    "    # flagging if the description contains the unwanted numbers but excluding the collection and 'button' types\n",
    "    for num in num_list:\n",
    "      if num in description:\n",
    "        description_temp = description\n",
    "        for word in words_list:\n",
    "          if word in description:\n",
    "            description_temp = description_temp.replace(word, '')\n",
    "            \n",
    "        if num in description_temp:\n",
    "          val = result_dict[num]\n",
    "          val.extend([style_code])\n",
    "          result_dict[num] = val\n",
    "\n",
    "  return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31c90825-9198-4068-b82f-922e593f776d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# flagging_system(temp)\n",
    "def get_flagged_data(temp):\n",
    "  sum_ = 0\n",
    "  unique_ids = []\n",
    "  for k, v in flagging_system(temp).items():    \n",
    "    unique_ids.extend(v)\n",
    "    sum_+=len(v)\n",
    "  unique_ids = list(set(unique_ids))\n",
    "  return (sum_,unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5602eef8-603d-4570-b0ec-9dfd22625c42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_result['product_description'] = final_result['product_description'].apply(lambda x : cleanup_description(x))\n",
    "# final_result['product_description'] = final_result['product_description'].apply(lambda x : capitalize_after_full_stop_description(x))\n",
    "temp = final_result.copy(deep=True)\n",
    "sum_,unique_ids = get_flagged_data(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04d4e918-0beb-4878-83b0-7660917925be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_output = temp[~temp['Style_Code'].isin(unique_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66d9fd91-5059-4026-906a-97e7cf5d53fe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_ids_df = df[df['Style_Code'].isin(unique_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2cd34ff-0590-4e8c-b0ce-9b94d192c99c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of stylecodes - 1 length of missed styles - 0\nRetries  - 1\nLength of flagged stylecodes - 0\n===========================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-ce647236-8e23-4a38-b931-ea/.ipykernel/12940/command-1722934488686471-3847538036:35: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n  final_result = final_result.append(result[iteration],ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "if not unique_ids_df.empty:\n",
    "  retries = 1\n",
    "  while retries<=5:\n",
    "    retry_df = df[df['Style_Code'].isin(unique_ids)]\n",
    "    # retry_dict = retry_df.rdd.map(lambda row: {key: value for key, value in row.asDict().items() if value is not None}).collect()\n",
    "    retry_dict = retry_df.apply(lambda row: row.dropna().to_dict(), axis=1).tolist()\n",
    "    descriptions_call = get_description(retry_dict)\n",
    "    final_result = descriptions_call[0]\n",
    "    missed_stylecodes = descriptions_call[1]\n",
    "    print('length of stylecodes -',len(final_result),'length of missed styles -',len(missed_stylecodes))\n",
    "    cnt=1\n",
    "    while len(missed_stylecodes)!=0:\n",
    "      missed_stylecodes_df = df[df['Style_Code'].isin(missed_stylecodes)]\n",
    "      # missed_stylecodes_dict = missed_stylecodes_df.rdd.map(lambda row: {key: value for key, value in row.asDict().items() if value is not None}).collect()\n",
    "      missed_stylecodes_dict = missed_stylecodes_df.apply(lambda row: row.dropna().to_dict(), axis=1).tolist()\n",
    "      descriptions_call = get_description(missed_stylecodes_dict)\n",
    "      missed_stylecodes_result = descriptions_call[0]\n",
    "      missed_stylecodes = descriptions_call[1]\n",
    "      print(\"Iteration -\",cnt)\n",
    "      print('length of stylecodes -',len(missed_stylecodes_result),'length of missed styles -',len(missed_stylecodes))\n",
    "      print(\"=======================================\")\n",
    "      cnt+=1\n",
    "      final_result = pd.concat([final_result,missed_stylecodes_result],axis=0)\n",
    "\n",
    "    final_result['product_description'] = final_result['product_description'].apply(lambda x : cleanup_description(x))\n",
    "    temp = final_result.copy(deep=True)  \n",
    "    if retries>4:\n",
    "      final_output = pd.concat([final_output,temp],axis=0)\n",
    "    else:\n",
    "      sum_,unique_ids = get_flagged_data(temp)\n",
    "      output = temp[~temp['Style_Code'].isin(unique_ids)]\n",
    "      print(\"Retries  -\",retries)\n",
    "      print('Length of flagged stylecodes -',len(unique_ids))\n",
    "      print('===========================')\n",
    "      final_output = pd.concat([final_output,output],axis=0)  \n",
    "      if len(unique_ids) ==0:\n",
    "        break\n",
    "    retries+=1\n",
    "else:\n",
    "  print('no style left')\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7183c329-4b4c-4a7d-ba38-c0b098796af8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def set_flagged_style(Style):\n",
    "    if Style in unique_ids:\n",
    "        return '1'\n",
    "    else:\n",
    "        return '0'\n",
    "\n",
    "# Add flagged_style column based on condition\n",
    "final_output['a_flagged_style'] = final_output['Style_Code'].apply(lambda x: set_flagged_style(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c548b3e1-2ffc-4c52-a463-2d1ae6720151",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Style_Code</th><th>Gender</th><th>Color</th><th>Fit</th><th>Occasion</th><th>Neck</th><th>Pattern</th><th>Sleeve</th><th>Cuff</th><th>Front_Opening</th><th>Sole_Material</th><th>Wash</th><th>Category</th><th>brand</th><th>Description</th><th>Power_Source</th><th>Shorts_Type</th><th>Shoe_Type</th><th>Accessory_Type</th><th>Waist_Rise</th><th>Suit_Front</th><th>Trouser_Front</th><th>Strap_Color</th><th>Short_Description</th><th>collection</th><th>product_description</th><th>Collection</th><th>Material</th><th>a_flagged_style</th></tr></thead><tbody><tr><td>BY11012149720</td><td>men</td><td>black</td><td>slim</td><td>athleisure</td><td></td><td>solid</td><td></td><td></td><td></td><td></td><td></td><td>casual trousers</td><td>Byford</td><td>Be the best you while rocking these trousers with a polo an smart shoes.</td><td></td><td></td><td></td><td></td><td>low rise</td><td></td><td></td><td></td><td>Black Solid Ankle Length Athleisure Men Slim Fit Casual Trouser</td><td></td><td>Looking for trendy yet functional casual wear? Check out Byford's black slim-fit casual trousers designed for athletic leisure for men. These pants offer a sleek silhouette thanks to their low waist-rise design, comes with a solid pattern, and falls perfectly on all kinds of shoes. Crafted with quality materials, our trousers are long-lasting, so you can enjoy our top-notch products in the long run. Take a step forward with our athleisure pants, and enjoy fashion and comfort at the same time.</td><td>null</td><td>null</td><td>0</td></tr><tr><td>TJ110124687313</td><td>women</td><td>red</td><td>regular</td><td>festive</td><td></td><td>solid</td><td></td><td></td><td></td><td></td><td></td><td>pants</td><td>Rangmanch</td><td>These pants with a kurta, a mini bag an fab heels are perfect for a housewarming.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Red Solid Blended Women Regular Fit Pant</td><td></td><td>Unleash your festive glam with Rangmanch's new release red pants for women. Take your chic look to another level with these regular-fit solid pants designed for a perfect festive occasion. Woven with premium quality fabric, these pants offer ultimate comfort and durability, while adding a pop of color to your wardrobe. Its soft touch and elegant texture make it ideal for a perfect social gathering look. Elevate your style without compromising on comfort with Rangmanch's comfy and stylish festive pants.</td><td>null</td><td>null</td><td>0</td></tr><tr><td>TA110127074227</td><td>men</td><td>green</td><td>regular</td><td>athleisure</td><td>round</td><td>solid</td><td>half</td><td></td><td></td><td></td><td></td><td>t-shirt</td><td>Ajile</td><td>Gear up for an intense set by wearing this T-shirt with track pants an sports shoes.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Green Solid Athleisure Half Sleeves Round Neck Men Regular Fit  T-Shirt</td><td></td><td>Experience comfort and breathability like no other with Ajile's Green Men's Regular Fit Athleisure T-shirt. The T-shirt exudes style and sophistication with its solid pattern and round neck design, while the half sleeves make it suitable for any occasion. Ajile's high-standard design ensures durability, making it ideal for everyday active wear. Unleash your active you like never before and showcase all that you are. Discover your style and begin your new journey with Ajile today.</td><td>null</td><td>null</td><td>0</td></tr><tr><td>TA11012707357</td><td>men</td><td>brown</td><td>regular</td><td>athleisure</td><td>round</td><td>solid</td><td>half</td><td></td><td></td><td></td><td></td><td>t-shirt</td><td>Ajile</td><td>Enjoy your sport to the fullest wearing this T-shirt with joggers an sports shoes.</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>Brown Solid Athleisure Half Sleeves Round Neck Men Regular Fit  T-Shirt</td><td></td><td>Looking for a versatile and comfortable wardrobe staple for your athleisure collection? Enter Ajile's men's brown regular-fit t-shirt. With a solid color and round neckline, this t-shirt is perfect for matching and layering with your favorite activewear pieces. The half-sleeves provide breathability for workouts, while the overall design exudes understated style suitable for social events. Add this to your wardrobe today for a practical yet stylish addition.</td><td>null</td><td>null</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "BY11012149720",
         "men",
         "black",
         "slim",
         "athleisure",
         "",
         "solid",
         "",
         "",
         "",
         "",
         "",
         "casual trousers",
         "Byford",
         "Be the best you while rocking these trousers with a polo an smart shoes.",
         "",
         "",
         "",
         "",
         "low rise",
         "",
         "",
         "",
         "Black Solid Ankle Length Athleisure Men Slim Fit Casual Trouser",
         "",
         "Looking for trendy yet functional casual wear? Check out Byford's black slim-fit casual trousers designed for athletic leisure for men. These pants offer a sleek silhouette thanks to their low waist-rise design, comes with a solid pattern, and falls perfectly on all kinds of shoes. Crafted with quality materials, our trousers are long-lasting, so you can enjoy our top-notch products in the long run. Take a step forward with our athleisure pants, and enjoy fashion and comfort at the same time.",
         null,
         null,
         "0"
        ],
        [
         "TJ110124687313",
         "women",
         "red",
         "regular",
         "festive",
         "",
         "solid",
         "",
         "",
         "",
         "",
         "",
         "pants",
         "Rangmanch",
         "These pants with a kurta, a mini bag an fab heels are perfect for a housewarming.",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         "Red Solid Blended Women Regular Fit Pant",
         "",
         "Unleash your festive glam with Rangmanch's new release red pants for women. Take your chic look to another level with these regular-fit solid pants designed for a perfect festive occasion. Woven with premium quality fabric, these pants offer ultimate comfort and durability, while adding a pop of color to your wardrobe. Its soft touch and elegant texture make it ideal for a perfect social gathering look. Elevate your style without compromising on comfort with Rangmanch's comfy and stylish festive pants.",
         null,
         null,
         "0"
        ],
        [
         "TA110127074227",
         "men",
         "green",
         "regular",
         "athleisure",
         "round",
         "solid",
         "half",
         "",
         "",
         "",
         "",
         "t-shirt",
         "Ajile",
         "Gear up for an intense set by wearing this T-shirt with track pants an sports shoes.",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         "Green Solid Athleisure Half Sleeves Round Neck Men Regular Fit  T-Shirt",
         "",
         "Experience comfort and breathability like no other with Ajile's Green Men's Regular Fit Athleisure T-shirt. The T-shirt exudes style and sophistication with its solid pattern and round neck design, while the half sleeves make it suitable for any occasion. Ajile's high-standard design ensures durability, making it ideal for everyday active wear. Unleash your active you like never before and showcase all that you are. Discover your style and begin your new journey with Ajile today.",
         null,
         null,
         "0"
        ],
        [
         "TA11012707357",
         "men",
         "brown",
         "regular",
         "athleisure",
         "round",
         "solid",
         "half",
         "",
         "",
         "",
         "",
         "t-shirt",
         "Ajile",
         "Enjoy your sport to the fullest wearing this T-shirt with joggers an sports shoes.",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         "",
         "Brown Solid Athleisure Half Sleeves Round Neck Men Regular Fit  T-Shirt",
         "",
         "Looking for a versatile and comfortable wardrobe staple for your athleisure collection? Enter Ajile's men's brown regular-fit t-shirt. With a solid color and round neckline, this t-shirt is perfect for matching and layering with your favorite activewear pieces. The half-sleeves provide breathability for workouts, while the overall design exudes understated style suitable for social events. Add this to your wardrobe today for a practical yet stylish addition.",
         null,
         null,
         "0"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Style_Code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Color",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Fit",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Occasion",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Neck",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Pattern",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Sleeve",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Cuff",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Front_Opening",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Sole_Material",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Wash",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Category",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "brand",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Power_Source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Shorts_Type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Shoe_Type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Accessory_Type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Waist_Rise",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Suit_Front",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Trouser_Front",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Strap_Color",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Short_Description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "collection",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "product_description",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Collection",
         "type": "\"void\""
        },
        {
         "metadata": "{}",
         "name": "Material",
         "type": "\"void\""
        },
        {
         "metadata": "{}",
         "name": "a_flagged_style",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = spark.createDataFrame(final_output)\n",
    "f.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a18959d6-d85a-448f-9296-e1522b50ebe0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4a893d8-975e-42dc-9a1d-5cff635c8480",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# f = f.select(col(\"Style_Code\").alias(\"a_stylecode\"),\n",
    "#                                    col(\"Short_Description\").alias(\"a_shortdescription\"),\n",
    "#                                    col(\"product_description\").alias(\"a_Longdescription\"),col('a_flagged_style'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bf7ba5c-addc-4663-b0ab-ed83cd7d2a0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d568f1-8b1e-484d-bee0-b1936f611b30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e1c5eec-ef3f-44f6-b3f1-b9b388da8788",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c09676-3e04-468b-978a-415e2234bc4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ec6eb08-5e3a-4703-afd3-a47d2ed5a15e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "PT_Gen_AI_Product_Descriptions",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
